{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# Install TensorFlow\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import joblib\n",
    "import pickle\n",
    "import itertools\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_label_map = {} \n",
    "#加入ans\n",
    "with open('./label.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        if len(line)>=3: \n",
    "            name = (line.split(' ')[0])\n",
    "            label = (line.split(' ')[1].replace('\\n','').replace('\\r',''))           \n",
    "            name_label_map[name] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20308, 64, 256, 1) (20308,)\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "labels = []\n",
    "try:\n",
    "    x = np.load('data_set_32.npy')\n",
    "    y = np.load('data_label.npy')\n",
    "except:\n",
    "    for root, dirs, files in os.walk('./image/', topdown=False): #train_gen\n",
    "        for name in files:\n",
    "            if(re.search(r\".*.png\", name)):\n",
    "                image = cv2.imread('./image/' + name)\n",
    "                image = cv2.resize(image, (32, 128) , interpolation=cv2.INTER_CUBIC)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                features.append(image)\n",
    "                labels.append(name_label_map[name])\n",
    "    x = np.array(features).reshape(-1,32,128,1)\n",
    "    y = np.array(list(map(int, labels)))\n",
    "\n",
    "    x = x/255.0\n",
    "    np.save('data_set_32.npy', x)\n",
    "    np.save('data_label.npy',y)\n",
    "    \n",
    "print(x.shape , y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 4) (2031,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=87)\n",
    "\n",
    "onehotencoder = OneHotEncoder()\n",
    "y_train = np.array(y_train).reshape(-1,1)\n",
    "y_test_onehot = np.array(y_test).reshape(-1,1)\n",
    "\n",
    "y_train = onehotencoder.fit_transform(y_train).toarray()\n",
    "y_test_onehot = onehotencoder.fit_transform(y_test_onehot).toarray()\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 62, 254, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 31, 127, 128)      0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 31, 127, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 29, 125, 128)      147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 62, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 111104)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                7110720   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 7,259,844\n",
      "Trainable params: 7,259,844\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model = tf.keras.Sequential([\n",
    "#     #tf.keras.layers.Flatten(input_shape=(256, 64)),\n",
    "#     tf.keras.layers.Dense(50000, activation='relu' , input_shape = x.shape[1:]),\n",
    "#     tf.keras.layers.Dropout(0.2),\n",
    "#     tf.keras.layers.Dense(4, activation='softmax')\n",
    "# ])\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "# Step 1 - Convolution\n",
    "model.add(Conv2D(128, (3, 3), input_shape = x.shape[1:], activation = 'relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "model.add(Conv2D(128, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "model.add(Flatten())\n",
    "               \n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(4, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "9000/9000 [==============================] - 131s 15ms/step - loss: 12.1043 - categorical_accuracy: 0.2490 - val_loss: 12.2337 - val_categorical_accuracy: 0.2410\n",
      "Epoch 2/20\n",
      "9000/9000 [==============================] - 134s 15ms/step - loss: 12.1041 - categorical_accuracy: 0.2490 - val_loss: 12.2337 - val_categorical_accuracy: 0.2410\n",
      "Epoch 3/20\n",
      "9000/9000 [==============================] - 137s 15ms/step - loss: 12.1041 - categorical_accuracy: 0.2490 - val_loss: 12.2337 - val_categorical_accuracy: 0.2410\n",
      "Epoch 4/20\n",
      "6228/9000 [===================>..........] - ETA: 40s - loss: 12.1062 - categorical_accuracy: 0.2489"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=1, epochs=20, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_test_onehot,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_test)\n",
    "y_pred = y_pred + 1\n",
    "\n",
    "print(y_pred.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    plt.ylim(-0.5, 3.5)\n",
    "\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "malware_label = {'1': 'adware', \n",
    "                '2': 'backdoor',\n",
    "                '3' : 'trojan',\n",
    "                '4' : 'worm'}\n",
    "\n",
    "target_names = [malware_label['1'],malware_label['2'] ,malware_label['3'],malware_label['4']]\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plot_confusion_matrix(cnf_matrix, classes=target_names,normalize=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: CNN_5000_32.model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"CNN_5000_32.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadmodel = tf.keras.models.load_model(\"CNN_first.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "286/286 [==============================] - 64s 225ms/step - loss: 0.1481 - categorical_accuracy: 0.9475 - val_loss: 0.6260 - val_categorical_accuracy: 0.8680\n",
      "Epoch 2/10\n",
      "286/286 [==============================] - 78s 274ms/step - loss: 0.1235 - categorical_accuracy: 0.9558 - val_loss: 0.7108 - val_categorical_accuracy: 0.8661\n",
      "Epoch 3/10\n",
      "286/286 [==============================] - 78s 274ms/step - loss: 0.1056 - categorical_accuracy: 0.9628 - val_loss: 0.8031 - val_categorical_accuracy: 0.8513\n",
      "Epoch 4/10\n",
      "286/286 [==============================] - 74s 259ms/step - loss: 0.0898 - categorical_accuracy: 0.9684 - val_loss: 0.7557 - val_categorical_accuracy: 0.8587\n",
      "Epoch 5/10\n",
      "286/286 [==============================] - 72s 253ms/step - loss: 0.0868 - categorical_accuracy: 0.9716 - val_loss: 0.7931 - val_categorical_accuracy: 0.8621\n",
      "Epoch 6/10\n",
      "286/286 [==============================] - 71s 247ms/step - loss: 0.0712 - categorical_accuracy: 0.9770 - val_loss: 0.8208 - val_categorical_accuracy: 0.8572\n",
      "Epoch 7/10\n",
      "286/286 [==============================] - 70s 246ms/step - loss: 0.0633 - categorical_accuracy: 0.9790 - val_loss: 0.8020 - val_categorical_accuracy: 0.8656\n",
      "Epoch 8/10\n",
      "286/286 [==============================] - 74s 259ms/step - loss: 0.0566 - categorical_accuracy: 0.9817 - val_loss: 0.9391 - val_categorical_accuracy: 0.8518\n",
      "Epoch 9/10\n",
      "286/286 [==============================] - 110s 383ms/step - loss: 0.0557 - categorical_accuracy: 0.9821 - val_loss: 0.8464 - val_categorical_accuracy: 0.8616\n",
      "Epoch 10/10\n",
      "286/286 [==============================] - 86s 302ms/step - loss: 0.0471 - categorical_accuracy: 0.9844 - val_loss: 0.9233 - val_categorical_accuracy: 0.8543\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x117ea2d6588>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadmodel.fit(x, y, batch_size=64, epochs=10, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: CNN_first.model\\assets\n"
     ]
    }
   ],
   "source": [
    "loadmodel.save(\"CNN_first.model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
