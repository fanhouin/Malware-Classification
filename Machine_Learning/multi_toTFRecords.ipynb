{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Num GPUs Available:  1\n"
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read image and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(81727,)\n"
    }
   ],
   "source": [
    "label_path = 'label_multi.csv'\n",
    "\n",
    "df = pd.read_csv(label_path)\n",
    "df = shuffle(df, random_state=87)\n",
    "\n",
    "img_name = df.Name.values\n",
    "image_paths = 'image_binvis_class_multi/' + img_name # add path to img name\n",
    "labels = df[['Adware','Backdoor','Ransom','Trojan','Worm']].values\n",
    "\n",
    "img_train, img_test, label_train, label_test = train_test_split(image_paths, labels, test_size=0.15, random_state=50)\n",
    "print(img_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "IMAGE_HEIGHT = 128\n",
    "IMAGE_WIDTH = 32\n",
    "IMAGE_DEPTH = 3\n",
    "\n",
    "BATCH_SIZE = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images and do some preprocsesses using tf functions\n",
    "def load_image(image_path, label):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=IMAGE_DEPTH)\n",
    "    img = tf.image.resize(img, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img = tf.divide(img,255.0)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<MapDataset shapes: ((128, 32, 3), (5,)), types: (tf.float32, tf.int64)>\n<MapDataset shapes: ((128, 32, 3), (5,)), types: (tf.float32, tf.int64)>\n"
    }
   ],
   "source": [
    "dataset_train = tf.data.Dataset.from_tensor_slices((img_train,label_train))\n",
    "dataset_train = dataset_train.map(load_image)\n",
    "\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices((img_test,label_test))\n",
    "dataset_test = dataset_test.map(load_image)\n",
    "\n",
    "print(dataset_train)\n",
    "print(dataset_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write dataset to TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following functions can be used to convert a value to a type compatible with tf.Example.\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_example(img, label):\n",
    "    \"\"\"\n",
    "    Creates a tf.Example message ready to be written to a file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a dictionary mapping the feature name to the tf.Example-compatible data type.\n",
    "    feature = {\n",
    "        'img': _bytes_feature(img.numpy().tostring()),\n",
    "        'label': _bytes_feature(label.numpy().tostring()),\n",
    "    }\n",
    "\n",
    "    # Create a Features message using tf.train.Example.\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    \n",
    "    return example_proto.SerializeToString()\n",
    "\n",
    "def tf_serialize_example(img, label):\n",
    "    tf_string = tf.py_function(\n",
    "        serialize_example,\n",
    "        [img, label],  # pass these args to the above function.\n",
    "        tf.string)      # the return type is `tf.string`.\n",
    "    return tf.reshape(tf_string,()) # The result is a scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_t = dataset_train.map(tf_serialize_example)\n",
    "filename_t = 'dataset_train_class.tfrecords'\n",
    "writer = tf.data.experimental.TFRecordWriter(filename_t)\n",
    "writer.write(dataset_t)\n",
    "\n",
    "dataset_t = dataset_test.map(tf_serialize_example)\n",
    "filename_t = 'dataset_test_class.tfrecords'\n",
    "writer = tf.data.experimental.TFRecordWriter(filename_t)\n",
    "writer.write(dataset_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}